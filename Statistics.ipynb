{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson\n",
    "corr_coeff, p_value = sp.stats.pearsonr(df[x], df[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_corr_CI(r, sample_size, alpha):\n",
    "    '''\n",
    "    will compute the ((1-alpha)*100)% confidence interval\n",
    "    of the correlation coefficient \"r\", according to the\n",
    "    size of the sample used to compute \"r\" called \"sample_size\"\n",
    "    \n",
    "    Implemented following those two links as reference : \n",
    "        -http://onlinestatbook.com/2/estimation/correlation_ci.html\n",
    "        -https://zhiyzuo.github.io/Pearson-Correlation-CI-in-Python/\n",
    "    According to the following link (https://stats.stackexchange.com/questions/18887/how-to-calculate-a-confidence-interval-for-spearmans-rank-correlation),\n",
    "    this calculation can also be applied to obtain a CI for a spearman correlation coefficient.\n",
    "    '''\n",
    "    \n",
    "    # The following formula breaks when the correlation is either -1 or 1 (because of arctanh)\n",
    "    if abs(r) == 1:\n",
    "        return np.NaN, np.NaN\n",
    "    \n",
    "    r_z = np.arctanh(r)\n",
    "    se = 1/np.sqrt(sample_size-3)\n",
    "    z = stats.norm.ppf(1-alpha/2)\n",
    "    return np.tanh((r_z-z*se, r_z+z*se))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_ps_corr(df):\n",
    "    '''\n",
    "    Applies the Pearson and Spearman correlation for the given dataframe and display the results. For\n",
    "    interpretation purposes, the sample size and a 95% confidence interval for both correlations \n",
    "    are also displayed.\n",
    "    '''\n",
    "    data_size = len(df)\n",
    "    print(f'Sample size : {data_size}')\n",
    "    \n",
    "    for corr_type in ['spearman', 'pearson']:\n",
    "                    \n",
    "        corr = float(df.corr(corr_type).iloc[1,0])\n",
    "        alpha = 0.05\n",
    "        lo, hi = compute_corr_CI(corr, len(df), alpha)\n",
    "                    \n",
    "        print('%s correlation: %.4f'%(corr_type.capitalize(), corr))\n",
    "        \n",
    "        if np.isnan(lo) or np.isnan(hi):\n",
    "            print('Note: It is not possible to calculate the  %d%% confidence interval here.'%((1-alpha)*100))\n",
    "        else:\n",
    "            print('with the following %d%% confidence interval for the %s correlation \\\"r\": %.4f ≤ r ≤ %.4f '%((1-alpha)*100,corr_type.capitalize(), lo, hi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping & Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(data, sample_nb, funs={'mean': np.mean, 'std': np.std, 'median': np.median}):\n",
    "    \"\"\"Generate statistics for data using bootstrapping\"\"\"\n",
    "    \n",
    "    funs_results = {}\n",
    "    \n",
    "    # Initialize arrays\n",
    "    for key in funs.keys():\n",
    "        funs_results.setdefault(key, np.zeros(sample_nb))\n",
    "    \n",
    "    # Compute result values of given functions for each bootstrap\n",
    "    for i in range(sample_nb):\n",
    "        sample = np.random.choice(data, data.shape[0], replace=True)\n",
    "        for key, value in funs_results.items():\n",
    "            value[i] = funs[key](sample)\n",
    "            funs_results[key] = value\n",
    "            \n",
    "    # Compute mean and standard deviation of bootstrap samples for all functions\n",
    "    for key, value in funs_results.items():\n",
    "        mean_value = np.mean(value)\n",
    "        std_value = np.std(value)\n",
    "        funs_results[key] = (mean_value, std_value, value)\n",
    "        \n",
    "    return funs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CI_intervals_overlapping(tag1_data, tag2_data, alpha=0.05):\n",
    "    \"\"\"Calculate confidence intervals of the data and check for overlapping\"\"\"\n",
    "    \n",
    "    # Compute 95% confidence interval for tag1\n",
    "    tag1_CI = (np.quantile(tag1_data, alpha/2), np.quantile(tag1_data, 1 - alpha/2))\n",
    "    (lower_tag1, upper_tag1) = tag1_CI\n",
    "    \n",
    "    # Compute 95% confidence interval for tag2\n",
    "    tag2_CI = (np.quantile(tag2_data, alpha/2), np.quantile(tag2_data, 1 - alpha/2))\n",
    "    (lower_tag2, upper_tag2) = tag2_CI\n",
    "    \n",
    "    # Check if tag1 confidence interval overlaps with tag2 confidence interval\n",
    "    overlapping = not ((lower_tag2 < lower_tag1 and upper_tag2 < lower_tag1)  \\\n",
    "                    or \\\n",
    "                    (lower_tag1 < lower_tag2 and upper_tag1 < lower_tag2))\n",
    "    \n",
    "    return tag1_CI, tag2_CI, overlapping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
