{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    '''\n",
    "    Build k randomly selected disjoint lists of indices to be used in \n",
    "    cross-validation. \n",
    "    '''\n",
    "    \n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create a random permutation of all numbers from 1 to num_row\n",
    "    indices = np.random.permutation(num_row)\n",
    "    \n",
    "    # Select k partitions of the random permutation\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                    for k in range(k_fold)]\n",
    "    \n",
    "    return np.array(k_indices)\n",
    "\n",
    "def cross_data(y, x, k_indices, k):\n",
    "    '''\n",
    "    Given a feature set, label set, and k disjoint lists of indices, \n",
    "    return the k-th partition (training + test for both features and labels). \n",
    "    '''\n",
    "\n",
    "    # get k'th subgroup in test, others in train:\n",
    "    x_tr = x.iloc[k_indices[np.arange(len(k_indices)) != k].flatten()]\n",
    "    x_te = x.iloc[k_indices[k]]\n",
    "\n",
    "    # Same for y\n",
    "    y_tr = y.iloc[k_indices[np.arange(len(k_indices)) != k].flatten()]\n",
    "    y_te = y.iloc[k_indices[k]]\n",
    "\n",
    "    return x_tr, x_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_backward_selection(y, x, k_fold, decision_boundary, metric):\n",
    "    '''\n",
    "    Perform greedy backward selection: until there are only one feature left,\n",
    "    try to remove each one of the remaining features and remove the one that \n",
    "    has the lowest score.\n",
    "    (Uses cross-validation with k_fold partitions).\n",
    "    '''\n",
    "    \n",
    "    selected_features = { x.shape[1] : (x, evaluate(y, x, k_fold, decision_boundary, metric, LogisticRegression())) }\n",
    "    \n",
    "    x_iter = x\n",
    "    \n",
    "    while len(x_iter.columns) > 1:\n",
    "        \n",
    "        best_x = None\n",
    "        best_result = -float('inf')\n",
    "        \n",
    "        for column in x_iter.columns:\n",
    "        \n",
    "            x_trim = x_iter.drop(column, axis=1)\n",
    "            \n",
    "            result = evaluate(y, x_trim, k_fold, decision_boundary, metric, LogisticRegression())\n",
    "            \n",
    "            if result > best_result:\n",
    "                \n",
    "                best_x = x_trim\n",
    "                best_result = result\n",
    "        \n",
    "        x_iter = best_x\n",
    "        selected_features[best_x.shape[1]] = (best_x, best_result)\n",
    "    \n",
    "    return selected_features\n",
    "    \n",
    "    \n",
    "def evaluate(y, x, k_fold, decision_boundary, metric, classifier_model):\n",
    "    '''\n",
    "    Calculate a given metric using cross-validation over k_fold partitions.\n",
    "    '''\n",
    "    \n",
    "    result = 0\n",
    "    \n",
    "    k_indices = build_k_indices(y, k_fold, 0)\n",
    "    \n",
    "    for k in range(0, k_fold):\n",
    "        \n",
    "        # Get the k-th split data set\n",
    "        x_tr, x_te, y_tr, y_te = cross_data(y, x, k_indices, k)\n",
    "        \n",
    "        # Train a classifier on the training data\n",
    "        classifier = classifier_model.fit(x_tr, y_tr)\n",
    "        \n",
    "        # Predict labels\n",
    "        y_pred = classify(classifier, x_te, decision_boundary)\n",
    "    \n",
    "        # Compute confusion matrix\n",
    "        result += metric(y_te, y_pred) / k_fold\n",
    "        \n",
    "    return result\n",
    "\n",
    "def accuracy_metric(y_te, y_pred):\n",
    "    '''\n",
    "    Accuracy of the classified labels.\n",
    "    '''\n",
    "\n",
    "    return accuracy(confusion_matrix(y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\displaystyle\\text{Precision} = \\frac{\\text{TP}}{\\text{TP}\\;+\\;\\text{FP}}$\n",
    "\n",
    "\n",
    "- $\\displaystyle\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$\n",
    "\n",
    "\n",
    "- $\\displaystyle\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}$\n",
    "\n",
    "\n",
    "- $\\displaystyle\\text{F1-Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_te, y_pred):\n",
    "    return [\n",
    "        [cm_item(y_te, y_pred, actual=1, pred= 1), cm_item(y_te, y_pred, actual=-1, pred= 1)],\n",
    "        [cm_item(y_te, y_pred, actual=1, pred=-1), cm_item(y_te, y_pred, actual=-1, pred=-1)]\n",
    "    ]\n",
    "\n",
    "tp = lambda m: m[0][0]\n",
    "fp = lambda m: m[0][1]\n",
    "fn = lambda m: m[1][0]\n",
    "tn = lambda m: m[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(m, pos=True):\n",
    "    if pos:\n",
    "        return tp(m) / (tp(m) + fp(m))\n",
    "    else:\n",
    "        return tn(m) / (tn(m) + fn(m))\n",
    "\n",
    "def recall(m, pos=True):\n",
    "    if pos:\n",
    "        return tp(m) / (tp(m) + fn(m))\n",
    "    else:\n",
    "        return tn(m) / (tn(m) + fp(m))\n",
    "\n",
    "def accuracy(m, pos=True):\n",
    "    return (tp(m) + tn(m)) / np.sum(m)\n",
    "\n",
    "def f1_score(m, pos=True):\n",
    "    return 2 * (precision(m, pos) * recall(m, pos)) / (precision(m, pos) + recall(m, pos))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
