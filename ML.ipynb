{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df = pd.read_csv('pokemon.csv').set_index('pid')\n",
    "combats_df = pd.read_csv('combats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardization, Normalization & Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_dummies_df = pd.get_dummies(pokemon_df['Class 1']) + pd.get_dummies(pokemon_df['Class 2'])\n",
    "stats_df = pokemon_df[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']]\n",
    "legendary_dummies_df = pokemon_df['Legendary'].astype(int)\n",
    "\n",
    "vectorized_pokemon_df = pd.concat([types_dummies_df, stats_df, legendary_dummies_df], axis=1)\n",
    "vectorized_pokemon_df = vectorized_pokemon_df.apply(standardize)\n",
    "    \n",
    "# Create a copy of combats with all pairs swapped\n",
    "combats_reversed_df = combats_df.copy()\n",
    "combats_reversed_df['First_pokemon'] = combats_df['Second_pokemon']\n",
    "combats_reversed_df['Second_pokemon'] = combats_df['First_pokemon']\n",
    "combats_reversed_df.index += combats_df.shape[0]\n",
    "\n",
    "# Create an augmented training dataset using both combats in normal and reversed forms\n",
    "augmented_combats_df = pd.concat([combats_df,combats_reversed_df])\n",
    "\n",
    "# Change labels into [0, 1]\n",
    "augmented_combats_df['w'] = np.where(augmented_combats_df['Winner'] == augmented_combats_df['First_pokemon'], 0, 1)\n",
    "\n",
    "# Vectorize combats\n",
    "left_vectorized_pokemon_df = vectorized_pokemon_df.reset_index().rename(columns=lambda c: c + '_left').rename(columns={'pid_left': 'First_pokemon'})\n",
    "right_vectorized_pokemon_df = vectorized_pokemon_df.reset_index().rename(columns=lambda c: c + '_right').rename(columns={'pid_right': 'Second_pokemon'})\n",
    "vectorized_combats_df = augmented_combats_df.merge(left_vectorized_pokemon_df, how='left', on='First_pokemon')\n",
    "vectorized_combats_df = vectorized_combats_df.merge(right_vectorized_pokemon_df, how='left', on='Second_pokemon')\n",
    "vectorized_combats_df = vectorized_combats_df.drop(columns=['Winner', 'First_pokemon', 'Second_pokemon'])\n",
    "\n",
    "# Create x and y as numpy arrays\n",
    "x = vectorized_combats_df.drop(columns=['w']).values\n",
    "y = vectorized_combats_df['w']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test / Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(x, y, train_ratio):\n",
    "    \n",
    "    # Generate split index at correct ratio\n",
    "    n = y.shape[0]\n",
    "    split = int(n * train_ratio)\n",
    "    \n",
    "    # Random permutation of all indices\n",
    "    random_indices = np.random.permutation(n)\n",
    "    \n",
    "    # Separate indices according to split\n",
    "    i_tr = random_indices[:split]\n",
    "    i_te = random_indices[split:]\n",
    "    \n",
    "    x_tr = x[i_tr]\n",
    "    x_te = x[i_te]\n",
    "    y_tr = y[i_tr]\n",
    "    y_te = y[i_te]\n",
    "    \n",
    "    # Return split\n",
    "    return x_tr, x_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data with .9 ratio\n",
    "x_tr, x_te, y_tr, y_te = test_train_split(x, y, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90000, 50), (10000, 50), (90000,), (10000,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_tr.shape, x_te.shape, y_tr.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    '''\n",
    "    Build k randomly selected disjoint lists of indices to be used in \n",
    "    cross-validation. \n",
    "    '''\n",
    "    \n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create a random permutation of all numbers from 1 to num_row\n",
    "    indices = np.random.permutation(num_row)\n",
    "    \n",
    "    # Select k partitions of the random permutation\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                    for k in range(k_fold)]\n",
    "    \n",
    "    return np.array(k_indices)\n",
    "\n",
    "def cross_data(x, y, k_indices, k):\n",
    "    '''\n",
    "    Given a feature set, label set, and k disjoint lists of indices, \n",
    "    return the k-th partition (training + test for both features and labels). \n",
    "    '''\n",
    "\n",
    "    # get k'th subgroup in test, others in train:\n",
    "    x_tr = x[k_indices[np.arange(len(k_indices)) != k].flatten()]\n",
    "    x_te = x[k_indices[k]]\n",
    "\n",
    "    # Same for y\n",
    "    y_tr = y[k_indices[np.arange(len(k_indices)) != k].flatten()]\n",
    "    y_te = y[k_indices[k]]\n",
    "\n",
    "    return x_tr, x_te, y_tr, y_te\n",
    "\n",
    "def cross_evaluate(x, y, k, evaluate):\n",
    "    '''\n",
    "    Calculate a given metric using cross-validation over k_fold partitions.\n",
    "    '''\n",
    "    \n",
    "    results = 0\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        \n",
    "        # Get split\n",
    "        x_tr, x_te, y_tr, y_te = cross_data(x, y, k, i)\n",
    "        \n",
    "        # Calculate results for current split\n",
    "        results += evaluate(x_tr, x_te, y_tr, y_te) / k\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build indices for cross-validation\n",
    "k_indices = build_k_indices(y, 5, seed=0)\n",
    "\n",
    "# Split data with .9 ratio\n",
    "x_tr, x_te, y_tr, y_te = cross_data(x, y, k_indices, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000, 50), (20000, 50), (80000,), (20000,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_tr.shape, x_te.shape, y_tr.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91025"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "\n",
    "rfc.fit(x_tr, y_tr).score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8858"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "cls.fit(x_tr, y_tr).score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Greedy Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_backward_selection(x, y, evaluate):\n",
    "    \n",
    "    # Initialize dataframes for scores and features selected\n",
    "    n = x.shape[1]\n",
    "    feature_masks = pd.DataFrame(np.full((n, n), False), columns=x.columns)\n",
    "    scores = pd.DataFrame(np.full(n, 0), columns=['score'])\n",
    "    \n",
    "    for step in range(0, n):\n",
    "\n",
    "        if step == 0:\n",
    "\n",
    "            # Calculate score and feature mask for initial step\n",
    "            feature_masks.loc[0] = True\n",
    "            scores.loc[0] = evaluate(x, y)\n",
    "\n",
    "        else :\n",
    "\n",
    "            features = x.columns[feature_masks.loc[step - 1]]\n",
    "\n",
    "            for feature in features:\n",
    "\n",
    "                feature_mask = (feature_masks.loc[step - 1]) & (x.columns != feature)\n",
    "\n",
    "                # Select all previously selected features except selected one\n",
    "                x_iter = x[x.columns[feature_mask]]\n",
    "\n",
    "                # Compute score with given set of features\n",
    "                score = evaluate(x_iter, y)\n",
    "\n",
    "                # If score is better than previous scores, store features\n",
    "                if score > scores.loc[step]['score']:\n",
    "                    scores.loc[step] = score\n",
    "                    feature_masks.loc[step][feature_mask] = True\n",
    "                    feature_masks.loc[step][~feature_mask] = False\n",
    "\n",
    "        # At the end of the loop, calculates score and feature\n",
    "        score_selected = scores.loc[step]\n",
    "        features_selected = x.columns[feature_masks.loc[step]]\n",
    "\n",
    "        print('step: {} - score: {} - features: {}'.format(step, score_selected, features_selected))\n",
    "\n",
    "    return scores, feature_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rfc(x_tr, x_te, y_tr, y_te):\n",
    "    rfc = RandomForestClassifier(n_estimators=10, max_depth=2)\n",
    "    return rfc.fit(x_tr, y_tr).score(x_te, y_te)\n",
    "\n",
    "scores, feature_masks = greedy_backward_selection(x.drop(columns=['First_pokemon', 'Second_pokemon']), y, lambda x, y: cross_evaluate(x, y, 5, evaluate_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rfc.feature_importances_, index=x.columns, columns=['feature_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\displaystyle\\text{Precision} = \\frac{\\text{TP}}{\\text{TP}\\;+\\;\\text{FP}}$\n",
    "\n",
    "\n",
    "- $\\displaystyle\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$\n",
    "\n",
    "\n",
    "- $\\displaystyle\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}$\n",
    "\n",
    "\n",
    "- $\\displaystyle\\text{F1-Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_item(y_te, y_pred, actual, pred):\n",
    "    return (y_te[(y_te == actual) & (y_pred == pred)]).shape[0]\n",
    "\n",
    "def confusion_matrix(y_te, y_pred):\n",
    "    return [\n",
    "        [cm_item(y_te, y_pred, actual=1, pred=1), cm_item(y_te, y_pred, actual=0, pred=1)],\n",
    "        [cm_item(y_te, y_pred, actual=1, pred=0), cm_item(y_te, y_pred, actual=0, pred=0)]\n",
    "    ]\n",
    "\n",
    "tp = lambda m: m[0][0]\n",
    "fp = lambda m: m[0][1]\n",
    "fn = lambda m: m[1][0]\n",
    "tn = lambda m: m[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(m, pos=True):\n",
    "    if pos:\n",
    "        return tp(m) / (tp(m) + fp(m))\n",
    "    else:\n",
    "        return tn(m) / (tn(m) + fn(m))\n",
    "\n",
    "def recall(m, pos=True):\n",
    "    if pos:\n",
    "        return tp(m) / (tp(m) + fn(m))\n",
    "    else:\n",
    "        return tn(m) / (tn(m) + fp(m))\n",
    "\n",
    "def accuracy(m, pos=True):\n",
    "    return (tp(m) + tn(m)) / np.sum(m)\n",
    "\n",
    "def f1_score(m, pos=True):\n",
    "    return 2 * (precision(m, pos) * recall(m, pos)) / (precision(m, pos) + recall(m, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8858397365532382"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8861934710991315"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8858"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8860165685198125"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cls.fit(x_tr, y_tr).predict(x_te)\n",
    "\n",
    "precision(confusion_matrix(y_te, y_pred))\n",
    "recall(confusion_matrix(y_te, y_pred))\n",
    "accuracy(confusion_matrix(y_te, y_pred))\n",
    "f1_score(confusion_matrix(y_te, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
